{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:23.514688Z",
     "start_time": "2022-03-03T05:59:23.512945Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set GPU number. This might work for several framework such as PyTorch, TensorFlow, Keras\n",
    "gpu_id = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:23.521626Z",
     "start_time": "2022-03-03T05:59:23.520358Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.377352Z",
     "start_time": "2022-03-03T05:59:23.524574Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.path.append('../../loglizer')\n",
    "    \n",
    "# from loglizer import dataloader\n",
    "# from loglizer.preprocessing import Vectorizer, Iterator\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.399070Z",
     "start_time": "2022-03-03T05:59:24.378242Z"
    }
   },
   "outputs": [],
   "source": [
    "# struct_log = '../data/HDFS/HDFS.log_structured.csv' # The structured log file\n",
    "\n",
    "#初始參數\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.mode = 'fedavg'  #FedBN,FedAvg,fedprox,fedopt,fedadagrad,fedadam 待加入scoffold\n",
    "        #所有方法都有使用Fedbn\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.99 #b1,b2 for adaptive opt\n",
    "        self.tau = 1e-2\n",
    "        self.batch = 32\n",
    "        self.lr = 1e-1\n",
    "        self.server_lr = 1e-1\n",
    "        self.server_momentum = 0.5\n",
    "        self.client_momentum = 0.9 # 0 is fedavg others is fedavgm\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.client_num = 5\n",
    "        self.wk_iters = 1 # training\n",
    "        self.num_workers = 2 # dataloader\n",
    "        self.mu = 1e-3\n",
    "        self.iters = 50 #epochs\n",
    "        self.local_epochs = 10\n",
    "        self.server_opt = 'sgd'\n",
    "        self.percent = 1\n",
    "#         self.early_stop = 500\n",
    "        self.window_size = 10\n",
    "        self.train_ratio = 0.5\n",
    "        self.split_type='sequential' # sequential, uniform\n",
    "\n",
    "        \n",
    "args = Parser()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed) \n",
    "random.seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.414106Z",
     "start_time": "2022-03-03T05:59:24.400157Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from logdeep.models.lstm import deeplog, loganomaly, robustlog\n",
    "from logdeep.tools.predict import Predicter\n",
    "from logdeep.tools.train import Trainer\n",
    "from logdeep.tools.utils import *\n",
    "\n",
    "# Config Parameters\n",
    "\n",
    "options = dict()\n",
    "options['data_dir'] = '../data/'\n",
    "options['window_size'] = 10\n",
    "options['device'] = 0\n",
    "\n",
    "# Smaple\n",
    "options['sample'] = \"sliding_window\"\n",
    "options['window_size'] = 10  # if fix_window\n",
    "\n",
    "# Features\n",
    "options['sequentials'] = True\n",
    "options['quantitatives'] = False\n",
    "options['semantics'] = False\n",
    "options['feature_num'] = sum(\n",
    "    [options['sequentials'], options['quantitatives'], options['semantics']])\n",
    "\n",
    "# Model\n",
    "options['input_size'] = 1\n",
    "options['hidden_size'] = 64\n",
    "options['num_layers'] = 2\n",
    "options['num_classes'] = 28\n",
    "\n",
    "# Train\n",
    "options['batch_size'] = 2048\n",
    "options['accumulation_step'] = 1\n",
    "\n",
    "options['optimizer'] = 'adam'\n",
    "options['lr'] = 1e-1\n",
    "options['max_epoch'] = args.local_epochs\n",
    "options['lr_step'] = (300, 350)\n",
    "options['lr_decay_ratio'] = 0.1\n",
    "\n",
    "options['resume_path'] = None\n",
    "options['model_name'] = \"deeplog\"\n",
    "options['save_dir'] = \"../result/deeplog/\"\n",
    "\n",
    "# Predict\n",
    "options['model_path'] = \"../result/deeplog/deeplog_last.pth\"\n",
    "options['num_candidates'] = 9\n",
    "\n",
    "seed_everything(seed=1234)\n",
    "\n",
    "\n",
    "def train():\n",
    "    trainer = Trainer(Model, options)\n",
    "    trainer.start_train()\n",
    "\n",
    "\n",
    "def predict():\n",
    "    predicter = Predicter(Model, options)\n",
    "    predicter.predict_unsupervised()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.416144Z",
     "start_time": "2022-03-03T05:59:24.414943Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(struct_log)\n",
    "# print(df.shape)\n",
    "\n",
    "# for i in range(args.client_num):\n",
    "#     bound = int(df.shape[0]/args.client_num)\n",
    "#     ddf = df[i* bound : (i+1)* bound]\n",
    "#     ddf.to_csv(\"../../loglizer/data/client_alldata/client_\"+str(i)+\".csv\", index=None)\n",
    "#     print('Client',i, ddf.shape)\n",
    "#     del ddf\n",
    "# del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.426029Z",
     "start_time": "2022-03-03T05:59:24.416844Z"
    }
   },
   "outputs": [],
   "source": [
    "class deeplog(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(deeplog, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size,\n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0 = features[0]\n",
    "        h0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(input0, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class loganomaly(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(loganomaly, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm0 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             num_layers,\n",
    "                             batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             num_layers,\n",
    "                             batch_first=True)\n",
    "        self.fc = nn.Linear(2 * hidden_size, num_keys)\n",
    "        self.attention_size = self.hidden_size\n",
    "\n",
    "        self.w_omega = Variable(\n",
    "            torch.zeros(self.hidden_size, self.attention_size))\n",
    "        self.u_omega = Variable(torch.zeros(self.attention_size))\n",
    "\n",
    "        self.sequence_length = 28\n",
    "\n",
    "    def attention_net(self, lstm_output):\n",
    "        output_reshape = torch.Tensor.reshape(lstm_output,\n",
    "                                              [-1, self.hidden_size])\n",
    "        attn_tanh = torch.tanh(torch.mm(output_reshape, self.w_omega))\n",
    "        attn_hidden_layer = torch.mm(\n",
    "            attn_tanh, torch.Tensor.reshape(self.u_omega, [-1, 1]))\n",
    "        exps = torch.Tensor.reshape(torch.exp(attn_hidden_layer),\n",
    "                                    [-1, self.sequence_length])\n",
    "        alphas = exps / torch.Tensor.reshape(torch.sum(exps, 1), [-1, 1])\n",
    "        alphas_reshape = torch.Tensor.reshape(alphas,\n",
    "                                              [-1, self.sequence_length, 1])\n",
    "        state = lstm_output\n",
    "        attn_output = torch.sum(state * alphas_reshape, 1)\n",
    "        return attn_output\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0, input1 = features[0], features[1]\n",
    "\n",
    "        h0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "        c0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "\n",
    "        out0, _ = self.lstm0(input0, (h0_0, c0_0))\n",
    "\n",
    "        h0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "        c0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "\n",
    "        out1, _ = self.lstm1(input1, (h0_1, c0_1))\n",
    "        multi_out = torch.cat((out0[:, -1, :], out1[:, -1, :]), -1)\n",
    "        out = self.fc(multi_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class robustlog(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(robustlog, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size,\n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0 = features[0]\n",
    "        h0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(input0, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.428341Z",
     "start_time": "2022-03-03T05:59:24.426748Z"
    }
   },
   "outputs": [],
   "source": [
    "# def datasplit(args, gpu_id = 1):\n",
    "#     train_loaders = []\n",
    "#     test_loaders = []\n",
    "#     hidden_size = 32\n",
    "#     num_directions = 2\n",
    "#     topk = 5\n",
    "    \n",
    "#     for i in range(args.client_num):\n",
    "#         struct_log = '../../loglizer/data/client_data/client_'+str(i)+\".csv\"\n",
    "#         label_file = '../../loglizer/data/HDFS/anomaly_label.csv' # The anomaly label file\n",
    "        \n",
    "#         (x_train, window_y_train, y_train), (x_test, window_y_test, y_test) = dataloader.load_HDFS(i, struct_log, label_file = label_file, window='session', window_size=args.window_size, train_ratio=args.train_ratio, split_type=args.split_type)\n",
    "#         feature_extractor = Vectorizer()\n",
    "#         train_dataset = feature_extractor.fit_transform(x_train, window_y_train, y_train)\n",
    "#         test_dataset = feature_extractor.transform(x_test, window_y_test, y_test)\n",
    "#         train_loader = Iterator(train_dataset, batch_size=args.batch, shuffle=True, num_workers=args.num_workers).iter\n",
    "#         test_loader = Iterator(test_dataset, batch_size=args.batch, shuffle=False, num_workers=args.num_workers).iter\n",
    "#         train_loaders.append(train_loader)\n",
    "#         test_loaders.append(test_loader)\n",
    "        \n",
    "#     server_model = DeepLog(num_labels=feature_extractor.num_labels, hidden_size=hidden_size, num_directions=num_directions, topk=topk).to(device)\n",
    "    \n",
    "#     return train_loaders, test_loaders, server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.430540Z",
     "start_time": "2022-03-03T05:59:24.429027Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loaders, test_loaders, server_model = datasplit(args, gpu_id = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:24.439664Z",
     "start_time": "2022-03-03T05:59:24.431623Z"
    }
   },
   "outputs": [],
   "source": [
    "def communication(args, server_model, models, client_weights, v, grad):\n",
    "    if args.mode.lower() == 'fedbn':\n",
    "        with torch.no_grad():\n",
    "            for key in server_model.state_dict().keys():\n",
    "                if 'bn' not in key: #非BN層都去交換\n",
    "                    temp = torch.zeros_like(server_model.state_dict()[key], dtype=torch.float32)\n",
    "                    for client_idx in range(client_num):\n",
    "                        temp += client_weights[client_idx] * models[client_idx].state_dict()[key]\n",
    "                    server_model.state_dict()[key].data.copy_(temp)\n",
    "                    for client_idx in range(client_num):\n",
    "                        models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])\n",
    "    \n",
    "    elif args.mode.lower() == 'fedadagrad':\n",
    "        with torch.no_grad():\n",
    "            for key, param in server_model.named_parameters():\n",
    "                temp = torch.zeros_like(server_model.state_dict()[key])\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    temp = temp + client_weights[client_idx] * models[client_idx].state_dict()[key]                          \n",
    "                param.grad = temp - param.data              \n",
    "                param.grad = torch.mul(grad[key], args.beta_1) + torch.mul(param.grad, 1-args.beta_1)\n",
    "                grad[key] = param.grad\n",
    "                v[key] = v[key] + param.grad**2\n",
    "                param.data = param.data + torch.mul(torch.div(param.grad, torch.add(torch.sqrt(v[key]),args.tau)), args.server_lr) \n",
    "\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])            \n",
    "    \n",
    "    elif args.mode.lower() == 'fedadam':\n",
    "        with torch.no_grad():\n",
    "            for key, param in server_model.named_parameters():                \n",
    "                temp = torch.zeros_like(server_model.state_dict()[key])\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    temp += client_weights[client_idx] * models[client_idx].state_dict()[key]                         \n",
    "                param.grad = temp - param.data              \n",
    "                param.grad = torch.mul(grad[key], args.beta_1) + torch.mul(param.grad, 1-args.beta_1) \n",
    "                grad[key] = param.grad                \n",
    "                v[key] = torch.mul(v[key], args.beta_2) + torch.mul(param.grad**2, 1-args.beta_2)\n",
    "                param.data = param.data + torch.mul(torch.div(param.grad, torch.add(torch.sqrt(v[key]),args.tau)), args.server_lr)\n",
    "                \n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for key in server_model.state_dict().keys():#遇到BN層就直接拿第一個client參數使用\n",
    "                # num_batches_tracked is a non trainable LongTensor and\n",
    "                # num_batches_tracked are the same for all clients for the given datasets\n",
    "                if 'num_batches_tracked' in key:\n",
    "                    server_model.state_dict()[key].data.copy_(models[0].state_dict()[key])\n",
    "                else:\n",
    "                    temp = torch.zeros_like(server_model.state_dict()[key]).to(device)\n",
    "                    for client_idx in range(len(client_weights)):\n",
    "                        temp += client_weights[client_idx] * models[client_idx].state_dict()[key]                        \n",
    "                    server_model.state_dict()[key].data.copy_(temp)#weight傳給server\n",
    "                    for client_idx in range(len(client_weights)):\n",
    "                        models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])        \n",
    "    return server_model, models, v, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.108837Z",
     "start_time": "2022-03-03T05:59:24.440446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Train epoch 0 ============\n",
      "Client  0\n",
      "File ../data/hdfs/hdfs_train, number of sessions 971\n",
      "File ../data/hdfs/hdfs_train, number of seqs 9420\n",
      "sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:00<00:00, 3493.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/hdfs/hdfs_test_normal, number of sessions 110673\n",
      "File ../data/hdfs/hdfs_test_normal, number of seqs 1058\n",
      "Find 9420 train logs, 1058 validation logs\n",
      "Train batch size 2048 ,Validation batch size 2048\n",
      "Starting epoch: 0 | phase: train | ⏰: 13:59:38 | Learning rate: 0.003125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-50bf1011c3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Client '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lloogg_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"['train']['epoch'].append(a_iter)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/chichen/FL/anomaly_detection/logdeep/logdeep/tools/train.py\u001b[0m in \u001b[0;36mstart_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_decay_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/chichen/FL/anomaly_detection/logdeep/logdeep/tools/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mtotal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log的type喔喔喔喔 喔'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# # setup model\n",
    "server_model = deeplog(input_size=options['input_size'],\n",
    "                    hidden_size=options['hidden_size'],\n",
    "                    num_layers=options['num_layers'],\n",
    "                    num_keys=options['num_classes']).to(device)\n",
    "# for adaptive velocity\n",
    "v = {}\n",
    "grad = {}\n",
    "for key in server_model.state_dict().keys():\n",
    "    v[key] = torch.add(torch.zeros_like(server_model.state_dict()[key],dtype=torch.float32),args.tau**2)\n",
    "    grad[key] = torch.zeros_like(server_model.state_dict()[key],dtype=torch.float32)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "# name of each datasets\n",
    "datasets = ['Client'+str(i) for i in range(args.client_num)]\n",
    "# federated client number\n",
    "client_num = len(datasets)\n",
    "client_weights = [1/client_num for i in range(client_num)]\n",
    "# each local client model\n",
    "models = [copy.deepcopy(server_model).to(device) for idx in range(client_num)]\n",
    "\n",
    "start_iter = 0\n",
    "\n",
    "lloogg_1 = {'train':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}, \n",
    "          'val':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}}\n",
    "lloogg_2 = {'train':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}, \n",
    "          'val':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}}\n",
    "lloogg_3 = {'train':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}, \n",
    "          'val':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}}\n",
    "lloogg_4 = {'train':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}, \n",
    "          'val':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}}\n",
    "lloogg_5 = {'train':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}, \n",
    "          'val':{'epoch':[], 'lr':[], 'time':[], 'loss':[]}}\n",
    "\n",
    "result_recall = {}\n",
    "result_precision = {}\n",
    "result_f1 = {}\n",
    "result_acc = {}\n",
    "for i in range(client_num):\n",
    "    result_recall[i] = []\n",
    "    result_precision[i] = []\n",
    "    result_f1[i] = []\n",
    "    result_acc[i] = []\n",
    "\n",
    "# Start training\n",
    "for a_iter in range(start_iter, args.iters):\n",
    "#     optimizers = [optim.SGD(params = models[idx].parameters(), lr=args.lr, momentum = args.client_momentum) for idx in range(client_num)]\n",
    "    for wi in range(args.wk_iters):\n",
    "        print(\"============ Train epoch {} ============\".format(wi + a_iter * args.wk_iters))\n",
    "        for client_idx, model in enumerate(models):\n",
    "            print('Client ', client_idx)\n",
    "            trainer = Trainer(model, options, args.client_num, client_idx)\n",
    "            trainer.start_train()\n",
    "            \n",
    "            exec('lloogg_'+str(client_idx+1)+\"['train']['epoch'].append(a_iter)\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['train']['lr'].append(trainer.log['train']['lr'][-1])\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['train']['time'].append(trainer.log['train']['time'][-1])\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['train']['loss'].append(trainer.log['train']['loss'][-1])\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['val']['epoch'].append(a_iter)\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['val']['lr'].append(trainer.log['valid']['lr'][-1])\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['val']['time'].append(trainer.log['valid']['time'][-1])\")\n",
    "            exec('lloogg_'+str(client_idx+1)+\"['val']['loss'].append(trainer.log['valid']['loss'][-1])\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # aggregation\n",
    "        server_model, models, v, grad = communication(args, server_model, models, client_weights, v, grad )\n",
    "        # Report loss after aggregation\n",
    "        print(\"============ Test epoch {} ============\".format(wi + a_iter * args.wk_iters))\n",
    "\n",
    "        for client_idx, model in enumerate(models):\n",
    "            print('Client ', client_idx)\n",
    "            predicter = Predicter(model, options, args.client_num, client_idx)\n",
    "            predicter.predict_unsupervised()\n",
    "            \n",
    "            result_recall[client_idx].append(predicter.recall)\n",
    "            result_precision[client_idx].append(predicter.precision)\n",
    "            result_f1[client_idx].append(predicter.f1)\n",
    "            result_acc[client_idx].append(predicter.acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.109761Z",
     "start_time": "2022-03-03T05:59:22.971Z"
    }
   },
   "outputs": [],
   "source": [
    "predicter_s = Predicter(server_model, options, 1, 0)\n",
    "predicter_s.predict_unsupervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.110273Z",
     "start_time": "2022-03-03T05:59:22.973Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, values in lloogg_1.items():\n",
    "    pd.DataFrame(values).to_csv(\"../result/deeplog/fedavg_10e_11/client_1_\" + key + \"_log.csv\", index=False)\n",
    "del key \n",
    "del values\n",
    "for key, values in lloogg_2.items():\n",
    "    pd.DataFrame(values).to_csv(\"../result/deeplog/fedavg_10e_11/client_2_\" + key + \"_log.csv\", index=False)\n",
    "del key \n",
    "del values\n",
    "for key, values in lloogg_3.items():\n",
    "    pd.DataFrame(values).to_csv(\"../result/deeplog/fedavg_10e_11/client_3_\" + key + \"_log.csv\", index=False)\n",
    "del key \n",
    "del values\n",
    "for key, values in lloogg_4.items():\n",
    "    pd.DataFrame(values).to_csv(\"../result/deeplog/fedavg_10e_11/client_4_\" + key + \"_log.csv\", index=False)\n",
    "del key \n",
    "del values\n",
    "for key, values in lloogg_5.items():\n",
    "    pd.DataFrame(values).to_csv(\"../result/deeplog/fedavg_10e_11/client_5_\" + key + \"_log.csv\", index=False)\n",
    "del key \n",
    "del values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.110770Z",
     "start_time": "2022-03-03T05:59:22.974Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(data=result_recall, orient='index').to_csv('../result/deeplog/fedavg_10e_11/recall.csv', header=False))\n",
    "(pd.DataFrame.from_dict(data=result_precision, orient='index').to_csv('../result/deeplog/fedavg_10e_11/precision.csv', header=False))\n",
    "(pd.DataFrame.from_dict(data=result_f1, orient='index').to_csv('../result/deeplog/fedavg_10e_11/f1.csv', header=False))\n",
    "(pd.DataFrame.from_dict(data=result_acc, orient='index').to_csv('../result/deeplog/fedavg_10e_11/acc.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.111253Z",
     "start_time": "2022-03-03T05:59:22.976Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(lloogg_1['train']['epoch'], lloogg_1['train']['loss'])\n",
    "plt.plot(lloogg_1['val']['epoch'], lloogg_1['val']['loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lloogg_2['train']['epoch'], lloogg_2['train']['loss'])\n",
    "plt.plot(lloogg_2['val']['epoch'], lloogg_2['val']['loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lloogg_3['train']['epoch'], lloogg_3['train']['loss'])\n",
    "plt.plot(lloogg_3['val']['epoch'], lloogg_3['val']['loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lloogg_4['train']['epoch'], lloogg_4['train']['loss'])\n",
    "plt.plot(lloogg_4['val']['epoch'], lloogg_4['val']['loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lloogg_5['train']['epoch'], lloogg_5['train']['loss'])\n",
    "plt.plot(lloogg_5['val']['epoch'], lloogg_5['val']['loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.111693Z",
     "start_time": "2022-03-03T05:59:22.979Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lloogg_1['train']['epoch'], lloogg_1['train']['loss'])\n",
    "plt.plot(lloogg_2['train']['epoch'], lloogg_2['train']['loss'])\n",
    "plt.plot(lloogg_3['train']['epoch'], lloogg_3['train']['loss'])\n",
    "plt.plot(lloogg_4['train']['epoch'], lloogg_4['train']['loss'])\n",
    "plt.plot(lloogg_5['train']['epoch'], lloogg_5['train']['loss'])\n",
    "# plt.plot(lloogg_1['val']['epoch'], lloogg_1['val']['loss'])\n",
    "plt.title('Train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1','2','3','4','5'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.112163Z",
     "start_time": "2022-03-03T05:59:22.981Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lloogg_1['val']['epoch'], lloogg_1['val']['loss'])\n",
    "plt.plot(lloogg_2['val']['epoch'], lloogg_2['val']['loss'])\n",
    "plt.plot(lloogg_3['val']['epoch'], lloogg_3['val']['loss'])\n",
    "plt.plot(lloogg_4['val']['epoch'], lloogg_4['val']['loss'])\n",
    "plt.plot(lloogg_5['val']['epoch'], lloogg_5['val']['loss'])\n",
    "# plt.plot(lloogg_1['val']['epoch'], lloogg_1['val']['loss'])\n",
    "plt.title('Validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1','2','3','4','5'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.112642Z",
     "start_time": "2022-03-03T05:59:22.988Z"
    }
   },
   "outputs": [],
   "source": [
    "result_record_f1 = pd.DataFrame.from_dict(data=result_f1, orient='index')\n",
    "result_record_f1 = np.mean(np.array(result_record_f1), axis = 0)\n",
    "result_record_f1 = result_record_f1.reshape(-1)\n",
    "\n",
    "result_record_acc = pd.DataFrame.from_dict(data=result_acc, orient='index')\n",
    "result_record_acc = np.mean(np.array(result_record_acc), axis = 0)\n",
    "result_record_acc = result_record_acc.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.113088Z",
     "start_time": "2022-03-03T05:59:22.990Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(client_num):\n",
    "    plt.plot(np.arange(args.iters), result_acc[i], label = 'Client '+ str(i+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:59:38.113564Z",
     "start_time": "2022-03-03T05:59:22.991Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(client_num):\n",
    "    plt.plot(np.arange(args.iters), result_f1[i], label =  'Client '+ str(i+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chi_env]",
   "language": "python",
   "name": "conda-env-chi_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
