{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:05.630051Z",
     "start_time": "2022-01-14T10:01:05.628150Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set GPU number. This might work for several framework such as PyTorch, TensorFlow, Keras\n",
    "gpu_id = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:05.633767Z",
     "start_time": "2022-01-14T10:01:05.632425Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.527512Z",
     "start_time": "2022-01-14T10:01:05.634562Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.path.append('../../loglizer')\n",
    "    \n",
    "# from loglizer import dataloader\n",
    "# from loglizer.preprocessing import Vectorizer, Iterator\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.540581Z",
     "start_time": "2022-01-14T10:01:06.528555Z"
    }
   },
   "outputs": [],
   "source": [
    "# struct_log = '../data/HDFS/HDFS.log_structured.csv' # The structured log file\n",
    "\n",
    "#初始參數\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.mode = 'fedavg'  #FedBN,FedAvg,fedprox,fedopt,fedadagrad,fedadam 待加入scoffold\n",
    "        #所有方法都有使用Fedbn\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.99 #b1,b2 for adaptive opt\n",
    "        self.tau = 1e-2\n",
    "        self.batch = 32\n",
    "        self.lr = 1e-2\n",
    "        self.server_lr = 1e-3\n",
    "        self.server_momentum = 0.5\n",
    "        self.client_momentum = 0.9 # 0 is fedavg others is fedavgm\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.client_num = 5\n",
    "        self.wk_iters = 1 # training\n",
    "        self.num_workers = 2 # dataloader\n",
    "        self.mu = 1e-3\n",
    "        self.iters = 500 #epochs\n",
    "        self.local_epoches = 1\n",
    "        self.server_opt = 'sgd'\n",
    "        self.percent = 1\n",
    "#         self.early_stop = 500\n",
    "        self.window_size = 10\n",
    "        self.train_ratio = 0.5\n",
    "        self.split_type='sequential' # sequential, uniform\n",
    "\n",
    "        \n",
    "args = Parser()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed) \n",
    "random.seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.554802Z",
     "start_time": "2022-01-14T10:01:06.541944Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from logdeep.models.lstm import deeplog, loganomaly, robustlog\n",
    "from logdeep.tools.predict import Predicter\n",
    "from logdeep.tools.train import Trainer\n",
    "from logdeep.tools.utils import *\n",
    "\n",
    "# Config Parameters\n",
    "\n",
    "options = dict()\n",
    "options['data_dir'] = '../data/'\n",
    "options['window_size'] = 10\n",
    "options['device'] = 0\n",
    "\n",
    "# Smaple\n",
    "options['sample'] = \"sliding_window\"\n",
    "options['window_size'] = 10  # if fix_window\n",
    "\n",
    "# Features\n",
    "options['sequentials'] = True\n",
    "options['quantitatives'] = False\n",
    "options['semantics'] = False\n",
    "options['feature_num'] = sum(\n",
    "    [options['sequentials'], options['quantitatives'], options['semantics']])\n",
    "\n",
    "# Model\n",
    "options['input_size'] = 1\n",
    "options['hidden_size'] = 64\n",
    "options['num_layers'] = 2\n",
    "options['num_classes'] = 28\n",
    "\n",
    "# Train\n",
    "options['batch_size'] = 2048\n",
    "options['accumulation_step'] = 1\n",
    "\n",
    "options['optimizer'] = 'adam'\n",
    "options['lr'] = 0.001\n",
    "options['max_epoch'] = 1\n",
    "options['lr_step'] = (300, 350)\n",
    "options['lr_decay_ratio'] = 0.1\n",
    "\n",
    "options['resume_path'] = None\n",
    "options['model_name'] = \"deeplog\"\n",
    "options['save_dir'] = \"../result/deeplog/\"\n",
    "\n",
    "# Predict\n",
    "options['model_path'] = \"../result/deeplog/deeplog_last.pth\"\n",
    "options['num_candidates'] = 9\n",
    "\n",
    "seed_everything(seed=1234)\n",
    "\n",
    "\n",
    "def train():\n",
    "    trainer = Trainer(Model, options)\n",
    "    trainer.start_train()\n",
    "\n",
    "\n",
    "def predict():\n",
    "    predicter = Predicter(Model, options)\n",
    "    predicter.predict_unsupervised()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.557264Z",
     "start_time": "2022-01-14T10:01:06.555799Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(struct_log)\n",
    "# print(df.shape)\n",
    "\n",
    "# for i in range(args.client_num):\n",
    "#     bound = int(df.shape[0]/args.client_num)\n",
    "#     ddf = df[i* bound : (i+1)* bound]\n",
    "#     ddf.to_csv(\"../../loglizer/data/client_alldata/client_\"+str(i)+\".csv\", index=None)\n",
    "#     print('Client',i, ddf.shape)\n",
    "#     del ddf\n",
    "# del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.571701Z",
     "start_time": "2022-01-14T10:01:06.558227Z"
    }
   },
   "outputs": [],
   "source": [
    "class deeplog(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(deeplog, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size,\n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0 = features[0]\n",
    "        h0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(input0, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class loganomaly(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(loganomaly, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm0 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             num_layers,\n",
    "                             batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             num_layers,\n",
    "                             batch_first=True)\n",
    "        self.fc = nn.Linear(2 * hidden_size, num_keys)\n",
    "        self.attention_size = self.hidden_size\n",
    "\n",
    "        self.w_omega = Variable(\n",
    "            torch.zeros(self.hidden_size, self.attention_size))\n",
    "        self.u_omega = Variable(torch.zeros(self.attention_size))\n",
    "\n",
    "        self.sequence_length = 28\n",
    "\n",
    "    def attention_net(self, lstm_output):\n",
    "        output_reshape = torch.Tensor.reshape(lstm_output,\n",
    "                                              [-1, self.hidden_size])\n",
    "        attn_tanh = torch.tanh(torch.mm(output_reshape, self.w_omega))\n",
    "        attn_hidden_layer = torch.mm(\n",
    "            attn_tanh, torch.Tensor.reshape(self.u_omega, [-1, 1]))\n",
    "        exps = torch.Tensor.reshape(torch.exp(attn_hidden_layer),\n",
    "                                    [-1, self.sequence_length])\n",
    "        alphas = exps / torch.Tensor.reshape(torch.sum(exps, 1), [-1, 1])\n",
    "        alphas_reshape = torch.Tensor.reshape(alphas,\n",
    "                                              [-1, self.sequence_length, 1])\n",
    "        state = lstm_output\n",
    "        attn_output = torch.sum(state * alphas_reshape, 1)\n",
    "        return attn_output\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0, input1 = features[0], features[1]\n",
    "\n",
    "        h0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "        c0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "\n",
    "        out0, _ = self.lstm0(input0, (h0_0, c0_0))\n",
    "\n",
    "        h0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "        c0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
    "                           self.hidden_size).to(device)\n",
    "\n",
    "        out1, _ = self.lstm1(input1, (h0_1, c0_1))\n",
    "        multi_out = torch.cat((out0[:, -1, :], out1[:, -1, :]), -1)\n",
    "        out = self.fc(multi_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class robustlog(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(robustlog, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size,\n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, features, device):\n",
    "        input0 = features[0]\n",
    "        h0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, input0.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(input0, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.575042Z",
     "start_time": "2022-01-14T10:01:06.573442Z"
    }
   },
   "outputs": [],
   "source": [
    "# def datasplit(args, gpu_id = 1):\n",
    "#     train_loaders = []\n",
    "#     test_loaders = []\n",
    "#     hidden_size = 32\n",
    "#     num_directions = 2\n",
    "#     topk = 5\n",
    "    \n",
    "#     for i in range(args.client_num):\n",
    "#         struct_log = '../../loglizer/data/client_data/client_'+str(i)+\".csv\"\n",
    "#         label_file = '../../loglizer/data/HDFS/anomaly_label.csv' # The anomaly label file\n",
    "        \n",
    "#         (x_train, window_y_train, y_train), (x_test, window_y_test, y_test) = dataloader.load_HDFS(i, struct_log, label_file = label_file, window='session', window_size=args.window_size, train_ratio=args.train_ratio, split_type=args.split_type)\n",
    "#         feature_extractor = Vectorizer()\n",
    "#         train_dataset = feature_extractor.fit_transform(x_train, window_y_train, y_train)\n",
    "#         test_dataset = feature_extractor.transform(x_test, window_y_test, y_test)\n",
    "#         train_loader = Iterator(train_dataset, batch_size=args.batch, shuffle=True, num_workers=args.num_workers).iter\n",
    "#         test_loader = Iterator(test_dataset, batch_size=args.batch, shuffle=False, num_workers=args.num_workers).iter\n",
    "#         train_loaders.append(train_loader)\n",
    "#         test_loaders.append(test_loader)\n",
    "        \n",
    "#     server_model = DeepLog(num_labels=feature_extractor.num_labels, hidden_size=hidden_size, num_directions=num_directions, topk=topk).to(device)\n",
    "    \n",
    "#     return train_loaders, test_loaders, server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.577847Z",
     "start_time": "2022-01-14T10:01:06.576146Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loaders, test_loaders, server_model = datasplit(args, gpu_id = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.591489Z",
     "start_time": "2022-01-14T10:01:06.578860Z"
    }
   },
   "outputs": [],
   "source": [
    "def communication(args, server_model, models, client_weights, v, grad):\n",
    "    if args.mode.lower() == 'fedbn':\n",
    "        with torch.no_grad():\n",
    "            for key in server_model.state_dict().keys():\n",
    "                if 'bn' not in key: #非BN層都去交換\n",
    "                    temp = torch.zeros_like(server_model.state_dict()[key], dtype=torch.float32)\n",
    "                    for client_idx in range(client_num):\n",
    "                        temp += client_weights[client_idx] * models[client_idx].state_dict()[key]\n",
    "                    server_model.state_dict()[key].data.copy_(temp)\n",
    "                    for client_idx in range(client_num):\n",
    "                        models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])\n",
    "    \n",
    "    elif args.mode.lower() == 'fedadagrad':\n",
    "        with torch.no_grad():\n",
    "            for key, param in server_model.named_parameters():\n",
    "                temp = torch.zeros_like(server_model.state_dict()[key])\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    temp = temp + client_weights[client_idx] * models[client_idx].state_dict()[key]                          \n",
    "                param.grad = temp - param.data              \n",
    "                param.grad = torch.mul(grad[key], args.beta_1) + torch.mul(param.grad, 1-args.beta_1)\n",
    "                grad[key] = param.grad\n",
    "                v[key] = v[key] + param.grad**2\n",
    "                param.data = param.data + torch.mul(torch.div(param.grad, torch.add(torch.sqrt(v[key]),args.tau)), args.server_lr) \n",
    "\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])            \n",
    "    \n",
    "    elif args.mode.lower() == 'fedadam':\n",
    "        with torch.no_grad():\n",
    "            for key, param in server_model.named_parameters():                \n",
    "                temp = torch.zeros_like(server_model.state_dict()[key])\n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    temp += client_weights[client_idx] * models[client_idx].state_dict()[key]                         \n",
    "                param.grad = temp - param.data              \n",
    "                param.grad = torch.mul(grad[key], args.beta_1) + torch.mul(param.grad, 1-args.beta_1) \n",
    "                grad[key] = param.grad                \n",
    "                v[key] = torch.mul(v[key], args.beta_2) + torch.mul(param.grad**2, 1-args.beta_2)\n",
    "                param.data = param.data + torch.mul(torch.div(param.grad, torch.add(torch.sqrt(v[key]),args.tau)), args.server_lr)\n",
    "                \n",
    "                for client_idx in range(len(client_weights)):\n",
    "                    models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for key in server_model.state_dict().keys():#遇到BN層就直接拿第一個client參數使用\n",
    "                # num_batches_tracked is a non trainable LongTensor and\n",
    "                # num_batches_tracked are the same for all clients for the given datasets\n",
    "                if 'num_batches_tracked' in key:\n",
    "                    server_model.state_dict()[key].data.copy_(models[0].state_dict()[key])\n",
    "                else:\n",
    "                    temp = torch.zeros_like(server_model.state_dict()[key]).to(device)\n",
    "                    for client_idx in range(len(client_weights)):\n",
    "                        temp += client_weights[client_idx] * models[client_idx].state_dict()[key]                        \n",
    "                    server_model.state_dict()[key].data.copy_(temp)#weight傳給server\n",
    "                    for client_idx in range(len(client_weights)):\n",
    "                        models[client_idx].state_dict()[key].data.copy_(server_model.state_dict()[key])        \n",
    "    return server_model, models, v, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.682496Z",
     "start_time": "2022-01-14T10:01:06.592525Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-44bd84916507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # setup model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m server_model = loganomaly(input_size=options['input_size'],\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     num_keys=options['num_classes'])\n",
      "\u001b[0;32m<ipython-input-7-16034f9f31f2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size, num_layers, num_keys)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         self.w_omega = Variable(\n\u001b[0m\u001b[1;32m     40\u001b[0m             torch.zeros(self.hidden_size, self.attention_size))\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_omega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "# # setup model\n",
    "server_model = loganomaly(input_size=options['input_size'],\n",
    "                    hidden_size=options['hidden_size'],\n",
    "                    num_layers=options['num_layers'],\n",
    "                    num_keys=options['num_classes'])\n",
    "# for adaptive velocity\n",
    "v = {}\n",
    "grad = {}\n",
    "for key in server_model.state_dict().keys():\n",
    "    v[key] = torch.add(torch.zeros_like(server_model.state_dict()[key],dtype=torch.float32),args.tau**2)\n",
    "    grad[key] = torch.zeros_like(server_model.state_dict()[key],dtype=torch.float32)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "# name of each datasets\n",
    "datasets = ['Client'+str(i) for i in range(args.client_num)]\n",
    "# federated client number\n",
    "client_num = len(datasets)\n",
    "client_weights = [1/client_num for i in range(client_num)]\n",
    "# each local client model\n",
    "models = [copy.deepcopy(server_model).to(device) for idx in range(client_num)]\n",
    "\n",
    "best_epoch = 0\n",
    "best_f1 = [0. for j in range(client_num)] \n",
    "start_iter = 0\n",
    "\n",
    "result_train_loss = {}\n",
    "result_train_sec_acc = {}\n",
    "result_train_win_acc = {}\n",
    "result_train_f1 = {}\n",
    "result_train_recall = {}\n",
    "result_train_precision = {}\n",
    "\n",
    "result_test_sec_acc = {}\n",
    "result_test_win_acc = {}\n",
    "result_test_f1 = {}\n",
    "result_test_recall = {}\n",
    "result_test_precision = {}\n",
    "\n",
    "for i in range(args.client_num):    \n",
    "    result_train_loss[i] = []\n",
    "    result_train_sec_acc[i] = []\n",
    "    result_train_win_acc[i] = []\n",
    "    result_train_f1[i] = []\n",
    "    result_train_recall[i] = []\n",
    "    result_train_precision[i] = []\n",
    "\n",
    "    result_test_sec_acc[i] = []\n",
    "    result_test_win_acc[i] = []\n",
    "    result_test_f1[i] = []\n",
    "    result_test_recall[i] = []\n",
    "    result_test_precision[i] = []\n",
    "\n",
    "# Start training\n",
    "for a_iter in range(start_iter, args.iters):\n",
    "#     optimizers = [optim.SGD(params = models[idx].parameters(), lr=args.lr, momentum = args.client_momentum) for idx in range(client_num)]\n",
    "    for wi in range(args.wk_iters):\n",
    "        print(\"============ Train epoch {} ============\".format(wi + a_iter * args.wk_iters))\n",
    "        for client_idx, model in enumerate(models):\n",
    "            print('Client ', client_idx)\n",
    "            trainer = Trainer(model, options, args.client_num, client_idx)\n",
    "            trainer.start_train()\n",
    "            \n",
    "#             train_loss = train(model, train_loaders[client_idx], optimizers[client_idx], device, args.local_epoches)\n",
    "#             result_train_loss[client_idx].append(train_loss)\n",
    "    with torch.no_grad():\n",
    "        # aggregation\n",
    "        server_model, models, v, grad = communication(args, server_model, models, client_weights, v, grad )\n",
    "        # Report loss after aggregation\n",
    "\n",
    "#         for client_idx, model in enumerate(models):\n",
    "#             tr_metrics = test(model, train_loaders[client_idx], device)\n",
    "#             result_train_sec_acc[client_idx].append(tr_metrics['session_acc'])\n",
    "#             result_train_win_acc[client_idx].append(tr_metrics['window_acc'])\n",
    "#             result_train_f1[client_idx].append(tr_metrics['f1'])\n",
    "#             result_train_recall[client_idx].append(tr_metrics['recall'])\n",
    "#             result_train_precision[client_idx].append(tr_metrics['precision'])\n",
    "            \n",
    "#             print(' {:<8s}| Loss: {:.4f} | Session Acc: {:.4f}| Window Acc: {:.4f} | F1: {:.4f} | Recall: {:.4f} | Precision: {:.4f} '.format(datasets[client_idx], result_train_loss[client_idx][-1], result_train_sec_acc[client_idx][-1], result_train_win_acc[client_idx][-1],\n",
    "#                                                                                 result_train_f1[client_idx][-1], result_train_recall[client_idx][-1], result_train_precision[client_idx][-1])) \n",
    "          \n",
    "        print(\"============ Test epoch {} ============\".format(wi + a_iter * args.wk_iters))\n",
    "#         # Validation\n",
    "#         val_f1_list = [None for j in range(client_num)]\n",
    "        for client_idx, model in enumerate(models):\n",
    "            print('Client ', client_idx)\n",
    "            predicter = Predicter(model, options, args.client_num, client_idx)\n",
    "            predicter.predict_unsupervised()\n",
    "#             te_metrics = test(model, test_loaders[client_idx], device)\n",
    "#             val_f1_list[client_idx] = te_metrics['f1']\n",
    "#             result_test_sec_acc[client_idx].append(te_metrics['session_acc'])\n",
    "#             result_test_win_acc[client_idx].append(te_metrics['window_acc'])\n",
    "#             result_test_f1[client_idx].append(te_metrics['f1'])\n",
    "#             result_test_recall[client_idx].append(te_metrics['recall'])\n",
    "#             result_test_precision[client_idx].append(te_metrics['precision'])\n",
    "            \n",
    "#             print(' {:<8s}| Session Acc: {:.4f}| Window Acc: {:.4f} | F1: {:.4f} | Recall: {:.4f} | Precision: {:.4f} '.format(datasets[client_idx], result_test_sec_acc[client_idx][-1], result_test_win_acc[client_idx][-1],\n",
    "#                                                                                 result_test_f1[client_idx][-1], result_test_recall[client_idx][-1], result_test_precision[client_idx][-1])) \n",
    "            \n",
    "#         # Record best\n",
    "#         if np.mean(val_f1_list) > np.mean(best_f1):\n",
    "#             for client_idx in range(client_num):\n",
    "#                 best_f1[client_idx] = val_f1_list[client_idx]\n",
    "#                 best_epoch = a_iter\n",
    "#                 best_changed=True\n",
    "\n",
    "# for client_idx in range(client_num):\n",
    "#     print(' Best {:<10s}| Epoch:{} |Test F1: {:.4f}'.format(datasets[client_idx], best_epoch, best_f1[client_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.683415Z",
     "start_time": "2022-01-14T10:01:05.142Z"
    }
   },
   "outputs": [],
   "source": [
    "# # test on global model\n",
    "# if args.mode.lower() == 'fedbn':\n",
    "#     pass\n",
    "# else:\n",
    "#     for client_idx in range(client_num):\n",
    "#         models[client_idx].load_state_dict(server_model.state_dict())\n",
    "        \n",
    "# for test_idx, test_loader in enumerate(test_loaders):\n",
    "#     metrics = test(server_model, test_loader, device)\n",
    "#     print(' {:<8s}| Session Acc: {:.4f}| Window Acc: {:.4f} | F1: {:.4f} | Recall: {:.4f} | Precision: {:.4f} '.format(datasets[test_idx], metrics['session_acc'], metrics['window_acc'], metrics['f1'], metrics['recall'], metrics['precision']))\n",
    "\n",
    "predicter = Predicter(server_model.to(device), options, 1, 0)\n",
    "predicter.predict_unsupervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.684007Z",
     "start_time": "2022-01-14T10:01:05.144Z"
    }
   },
   "outputs": [],
   "source": [
    "# (pd.DataFrame.from_dict(data=result_train_loss, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_loss.csv', header=False))\n",
    "\n",
    "# (pd.DataFrame.from_dict(data=result_train_sec_acc, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_sec_acc.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_train_win_acc, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_win_acc.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_train_f1, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_f1.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_train_recall, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_recall.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_train_precision, orient='index').to_csv('../data/result_all/Fedavg_232_1_train_precision.csv', header=False))\n",
    "\n",
    "# (pd.DataFrame.from_dict(data=result_test_sec_acc, orient='index').to_csv('../data/result_all/Fedavg_232_1_test_sec_acc.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_test_win_acc, orient='index').to_csv('../data/result_all/Fedavg_232_1_test_win_acc.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_test_f1, orient='index').to_csv('../data/result_all/Fedavg_232_1_test_f1.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_test_recall, orient='index').to_csv('../data/result_all/Fedavg_232_1_test_recall.csv', header=False))\n",
    "# (pd.DataFrame.from_dict(data=result_test_precision, orient='index').to_csv('../data/result_all/Fedavg_232_1_test_precision.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.684581Z",
     "start_time": "2022-01-14T10:01:05.145Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_loss[i], label = datasets[i])\n",
    "# plt.title('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_sec_acc[i], label = datasets[i])\n",
    "# plt.title('Session Acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_win_acc[i], label = datasets[i])\n",
    "# plt.title('Window Acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_f1[i], label = datasets[i])\n",
    "# plt.title('F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_recall[i], label = datasets[i])\n",
    "# plt.title('Recall')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_train_precision[i], label = datasets[i])\n",
    "# plt.title('Precison')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.685263Z",
     "start_time": "2022-01-14T10:01:05.147Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_test_sec_acc[i], label = datasets[i])\n",
    "# plt.title('Session Acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_test_win_acc[i], label = datasets[i])\n",
    "# plt.title('Window Acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_test_f1[i], label = datasets[i])\n",
    "# plt.title('F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_test_recall[i], label = datasets[i])\n",
    "# plt.title('Recall')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(client_num):\n",
    "#     plt.plot(np.arange(args.iters), result_test_precision[i], label = datasets[i])\n",
    "# plt.title('Precison')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.686054Z",
     "start_time": "2022-01-14T10:01:05.150Z"
    }
   },
   "outputs": [],
   "source": [
    "# result_record_train = pd.DataFrame.from_dict(data=result_train_f1, orient='index')\n",
    "# result_record_train = np.mean(np.array(result_record_train), axis = 0)\n",
    "# result_record_train = result_record_train.reshape(-1)\n",
    "\n",
    "# result_record_test = pd.DataFrame.from_dict(data=result_test_f1, orient='index')\n",
    "# result_record_test = np.mean(np.array(result_record_test), axis = 0)\n",
    "# result_record_test = result_record_test.reshape(-1)\n",
    "\n",
    "# plt.plot(np.arange(args.iters), result_record_train, label = 'Train')\n",
    "# plt.plot(np.arange(args.iters), result_record_test, label = 'Test')\n",
    "# plt.title('Average F1 score')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T10:01:06.686901Z",
     "start_time": "2022-01-14T10:01:05.154Z"
    }
   },
   "outputs": [],
   "source": [
    "# result_record_train_loss = pd.DataFrame.from_dict(data=result_train_loss, orient='index')\n",
    "# result_record_train_loss = np.mean(np.array(result_record_train_loss), axis = 0)\n",
    "# result_record_train_loss = result_record_train_loss.reshape(-1)\n",
    "\n",
    "\n",
    "# plt.plot(np.arange(args.iters), result_record_train_loss, label = 'Train')\n",
    "# plt.title('Average train loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chi_env]",
   "language": "python",
   "name": "conda-env-chi_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
